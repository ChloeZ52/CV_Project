{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import MySQLdb\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.sampler as smp\n",
    "#from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import dataset\n",
    "import dataLoader\n",
    "import configure as cf\n",
    "import plot_utils as utils\n",
    "import train_function as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transform function, define trainset and valset\n",
    "#AlexNet requires the input size of 224*224*3\n",
    "imgTransform = transforms.Compose([transforms.Scale((224)),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor()                       \n",
    "                            ])\n",
    "trainLoader, valLoader = dataLoader.get_train_valid_loader(cf.photo_url,50,32,'food',imgTransform,0.1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define train model\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = True):\n",
    "    \n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    \n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0)<50 or stars.size(0)<50: break\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                stars = stars.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            #set a rule: if prediction values is between real_value-0.5 and real_value+0.5, correct+1\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            larger = (pre_star.view(50) >= (stars.data-0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(50) <= (stars.data+0.5)).type(torch.IntTensor)\n",
    "            correct += (larger+littler).eq(2).sum() \n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "        train_accuracy.append(100 * correct / counter)\n",
    "        train_loss.append(cum_loss / (1 + i))\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0)<50 or stars.size(0)<50: break\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                stars = stars.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            larger = (pre_star.view(50) >= (stars.data-0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(50) <= (stars.data+0.5)).type(torch.IntTensor)\n",
    "            correct += (larger+littler).eq(2).sum() \n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "        val_accuracy.append(100 * correct / counter)\n",
    "        val_loss.append(cum_loss / (1 + i))\n",
    "    return [train_accuracy,val_accuracy,train_loss,val_loss]\n",
    "            \n",
    "#define learningRate\n",
    "learningRate = 1e-2 \n",
    "\n",
    "# Definition of our network.\n",
    "# network = models.alexnet(pretrained = True, num_classes=1)\n",
    "network = models.alexnet(pretrained = False, num_classes=1)\n",
    "\n",
    "#Definition of our loss.\n",
    "#The MSELoss function (input? output?)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "result = []\n",
    "# Train the previously defined model.\n",
    "result = train.train_model(network, criterion, optimizer, trainLoader, valLoader,\n",
    "                           n_epochs = 20, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_loss(result[2],result[3])\n",
    "utils.plot_accuracy(result[0],result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
