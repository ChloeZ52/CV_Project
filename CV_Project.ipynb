{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import MySQLdb\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.sampler as smp\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import dataset\n",
    "import dataLoader\n",
    "import configure as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121267 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 729/121267 [00:00<00:16, 7288.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After search photo, find result: 121267\n",
      "Start search stars for each photo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  1%|          | 1432/121267 [00:00<00:16, 7180.70it/s]\u001b[A\n",
      "  2%|▏         | 2160/121267 [00:00<00:16, 7209.73it/s]\u001b[A\n",
      "  2%|▏         | 2903/121267 [00:00<00:16, 7272.72it/s]\u001b[A\n",
      "  3%|▎         | 3636/121267 [00:00<00:16, 7286.72it/s]\u001b[A\n",
      "  4%|▎         | 4362/121267 [00:00<00:16, 7276.56it/s]\u001b[A\n",
      "  4%|▍         | 5076/121267 [00:00<00:16, 7234.43it/s]\u001b[A\n",
      "  5%|▍         | 5804/121267 [00:00<00:15, 7245.81it/s]\u001b[A\n",
      "  5%|▌         | 6539/121267 [00:00<00:15, 7218.85it/s]\u001b[A\n",
      "  6%|▌         | 7269/121267 [00:01<00:15, 7240.48it/s]\u001b[A\n",
      "  7%|▋         | 7973/121267 [00:01<00:16, 6841.33it/s]\u001b[A\n",
      "  7%|▋         | 8713/121267 [00:01<00:16, 6997.76it/s]\u001b[A\n",
      "  8%|▊         | 9448/121267 [00:01<00:15, 7044.41it/s]\u001b[A\n",
      "  8%|▊         | 10180/121267 [00:01<00:15, 7122.60it/s]\u001b[A\n",
      "  9%|▉         | 10925/121267 [00:01<00:15, 7164.16it/s]\u001b[A\n",
      " 10%|▉         | 11647/121267 [00:01<00:15, 7178.55it/s]\u001b[A\n",
      " 10%|█         | 12398/121267 [00:01<00:15, 7220.71it/s]\u001b[A\n",
      " 11%|█         | 13126/121267 [00:01<00:14, 7236.30it/s]\u001b[A\n",
      " 11%|█▏        | 13855/121267 [00:01<00:14, 7197.10it/s]\u001b[A\n",
      " 12%|█▏        | 14599/121267 [00:02<00:14, 7266.16it/s]\u001b[A\n",
      " 13%|█▎        | 15349/121267 [00:02<00:14, 7275.64it/s]\u001b[A\n",
      " 13%|█▎        | 16077/121267 [00:02<00:14, 7276.58it/s]\u001b[A\n",
      " 14%|█▍        | 16817/121267 [00:02<00:14, 7251.66it/s]\u001b[A\n",
      " 14%|█▍        | 17548/121267 [00:02<00:14, 7265.97it/s]\u001b[A\n",
      " 15%|█▌        | 18291/121267 [00:02<00:14, 7258.08it/s]\u001b[A\n",
      " 16%|█▌        | 19027/121267 [00:02<00:14, 7285.72it/s]\u001b[A\n",
      " 16%|█▋        | 19786/121267 [00:02<00:13, 7318.67it/s]\u001b[A\n",
      " 17%|█▋        | 20521/121267 [00:02<00:13, 7323.24it/s]\u001b[A\n",
      " 18%|█▊        | 21261/121267 [00:02<00:13, 7288.58it/s]\u001b[A\n",
      " 18%|█▊        | 22011/121267 [00:03<00:13, 7350.01it/s]\u001b[A\n",
      " 19%|█▉        | 22764/121267 [00:03<00:13, 7340.59it/s]\u001b[A\n",
      " 19%|█▉        | 23499/121267 [00:03<00:13, 7311.55it/s]\u001b[A\n",
      " 20%|█▉        | 24232/121267 [00:03<00:13, 7291.11it/s]\u001b[A\n",
      " 21%|██        | 24986/121267 [00:03<00:13, 7331.39it/s]\u001b[A\n",
      " 21%|██        | 25724/121267 [00:03<00:13, 7318.52it/s]\u001b[A\n",
      "\n",
      " 22%|██▏       | 26468/121267 [00:03<00:12, 7323.77it/s]\u001b[A\n",
      " 22%|██▏       | 27212/121267 [00:03<00:12, 7331.58it/s]\u001b[A\n",
      " 23%|██▎       | 27947/121267 [00:03<00:12, 7308.49it/s]\u001b[A\n",
      " 24%|██▎       | 28690/121267 [00:03<00:12, 7314.51it/s]\u001b[A\n",
      " 24%|██▍       | 29432/121267 [00:04<00:12, 7310.60it/s]\u001b[A\n",
      " 25%|██▍       | 30176/121267 [00:04<00:12, 7322.43it/s]\u001b[A\n",
      " 26%|██▌       | 30935/121267 [00:04<00:12, 7369.44it/s]\u001b[A\n",
      " 26%|██▌       | 31688/121267 [00:04<00:12, 7391.48it/s]\u001b[A\n",
      " 27%|██▋       | 32444/121267 [00:04<00:11, 7403.83it/s]\u001b[A\n",
      " 27%|██▋       | 33185/121267 [00:04<00:11, 7344.57it/s]\u001b[A\n",
      " 28%|██▊       | 33933/121267 [00:04<00:11, 7381.34it/s]\u001b[A\n",
      " 29%|██▊       | 34679/121267 [00:04<00:11, 7348.33it/s]\u001b[A\n",
      " 29%|██▉       | 35414/121267 [00:04<00:11, 7284.16it/s]\u001b[A\n",
      " 30%|██▉       | 36143/121267 [00:04<00:11, 7247.43it/s]\u001b[A\n",
      " 30%|███       | 36888/121267 [00:05<00:11, 7283.91it/s]\u001b[A\n",
      " 31%|███       | 37619/121267 [00:05<00:11, 7251.94it/s]\u001b[A\n",
      " 32%|███▏      | 38349/121267 [00:05<00:11, 7238.96it/s]\u001b[A\n",
      " 32%|███▏      | 39076/121267 [00:05<00:11, 7202.55it/s]\u001b[A\n",
      " 33%|███▎      | 39811/121267 [00:05<00:11, 7229.18it/s]\u001b[A\n",
      " 33%|███▎      | 40551/121267 [00:05<00:11, 7235.69it/s]\u001b[A\n",
      " 34%|███▍      | 41280/121267 [00:05<00:11, 7235.12it/s]\u001b[A\n",
      " 35%|███▍      | 42017/121267 [00:05<00:10, 7235.98it/s]\u001b[A\n",
      " 35%|███▌      | 42771/121267 [00:05<00:10, 7306.05it/s]\u001b[A\n",
      " 36%|███▌      | 43531/121267 [00:05<00:10, 7351.90it/s]\u001b[A\n",
      " 37%|███▋      | 44275/121267 [00:06<00:10, 7359.65it/s]\u001b[A\n",
      " 37%|███▋      | 45012/121267 [00:06<00:10, 7309.59it/s]\u001b[A\n",
      " 38%|███▊      | 45758/121267 [00:06<00:10, 7351.94it/s]\u001b[A\n",
      " 38%|███▊      | 46522/121267 [00:06<00:10, 7377.97it/s]\u001b[A\n",
      " 39%|███▉      | 47266/121267 [00:06<00:10, 7393.58it/s]\u001b[A\n",
      " 40%|███▉      | 48024/121267 [00:06<00:09, 7391.51it/s]\u001b[A\n",
      " 40%|████      | 48764/121267 [00:06<00:09, 7362.21it/s]\u001b[A\n",
      " 41%|████      | 49501/121267 [00:06<00:09, 7328.76it/s]\u001b[A\n",
      " 41%|████▏     | 50236/121267 [00:06<00:09, 7312.42it/s]\u001b[A\n",
      " 42%|████▏     | 50989/121267 [00:07<00:09, 7338.79it/s]\u001b[A\n",
      " 43%|████▎     | 51736/121267 [00:07<00:09, 7342.43it/s]\u001b[A\n",
      " 43%|████▎     | 52479/121267 [00:07<00:09, 7343.61it/s]\u001b[A\n",
      " 44%|████▍     | 53214/121267 [00:07<00:09, 7283.62it/s]\u001b[A\n",
      " 44%|████▍     | 53943/121267 [00:07<00:09, 7250.77it/s]\u001b[A\n",
      " 45%|████▌     | 54691/121267 [00:07<00:09, 7293.63it/s]\u001b[A\n",
      " 46%|████▌     | 55421/121267 [00:07<00:09, 7194.15it/s]\u001b[A\n",
      " 46%|████▋     | 56141/121267 [00:07<00:09, 7183.71it/s]\u001b[A\n",
      " 47%|████▋     | 56894/121267 [00:07<00:08, 7238.16it/s]\u001b[A\n",
      " 48%|████▊     | 57636/121267 [00:07<00:08, 7280.52it/s]\u001b[A\n",
      " 48%|████▊     | 58398/121267 [00:08<00:08, 7323.18it/s]\u001b[A\n",
      " 49%|████▉     | 59133/121267 [00:08<00:08, 7328.77it/s]\u001b[A\n",
      " 49%|████▉     | 59872/121267 [00:08<00:08, 7290.58it/s]\u001b[A\n",
      " 50%|████▉     | 60612/121267 [00:08<00:08, 7322.28it/s]\u001b[A\n",
      " 51%|█████     | 61373/121267 [00:08<00:08, 7350.74it/s]\u001b[A\n",
      " 51%|█████     | 62117/121267 [00:08<00:08, 7374.46it/s]\u001b[A\n",
      " 52%|█████▏    | 62877/121267 [00:08<00:07, 7383.17it/s]\u001b[A\n",
      " 52%|█████▏    | 63618/121267 [00:08<00:07, 7387.25it/s]\u001b[A\n",
      " 53%|█████▎    | 64386/121267 [00:08<00:07, 7419.38it/s]\u001b[A\n",
      " 54%|█████▎    | 65129/121267 [00:08<00:07, 7321.95it/s]\u001b[A\n",
      " 54%|█████▍    | 65862/121267 [00:09<00:07, 7299.94it/s]\u001b[A\n",
      " 55%|█████▍    | 66618/121267 [00:09<00:07, 7342.65it/s]\u001b[A\n",
      " 56%|█████▌    | 67370/121267 [00:09<00:07, 7370.76it/s]\u001b[A\n",
      " 56%|█████▌    | 68108/121267 [00:09<00:07, 7302.61it/s]\u001b[A\n",
      " 57%|█████▋    | 68839/121267 [00:09<00:07, 7299.71it/s]\u001b[A\n",
      " 57%|█████▋    | 69578/121267 [00:09<00:07, 7271.54it/s]\u001b[A\n",
      " 58%|█████▊    | 70306/121267 [00:09<00:07, 7253.47it/s]\u001b[A\n",
      " 59%|█████▊    | 71040/121267 [00:09<00:06, 7234.14it/s]\u001b[A\n",
      " 59%|█████▉    | 71764/121267 [00:09<00:06, 7204.75it/s]\u001b[A\n",
      " 60%|█████▉    | 72485/121267 [00:09<00:06, 7158.99it/s]\u001b[A\n",
      " 60%|██████    | 73211/121267 [00:10<00:06, 7177.31it/s]\u001b[A\n",
      " 61%|██████    | 73934/121267 [00:10<00:06, 7148.87it/s]\u001b[A\n",
      " 62%|██████▏   | 74649/121267 [00:10<00:06, 7122.74it/s]\u001b[A\n",
      " 62%|██████▏   | 75377/121267 [00:10<00:06, 7135.47it/s]\u001b[A\n",
      " 63%|██████▎   | 76128/121267 [00:10<00:06, 7218.49it/s]\u001b[A\n",
      " 63%|██████▎   | 76884/121267 [00:10<00:06, 7284.72it/s]\u001b[A\n",
      " 64%|██████▍   | 77632/121267 [00:10<00:05, 7319.60it/s]\u001b[A\n",
      " 65%|██████▍   | 78366/121267 [00:10<00:05, 7289.97it/s]\u001b[A\n",
      " 65%|██████▌   | 79096/121267 [00:10<00:05, 7246.93it/s]\u001b[A\n",
      " 66%|██████▌   | 79823/121267 [00:10<00:05, 7244.25it/s]\u001b[A\n",
      " 66%|██████▋   | 80579/121267 [00:11<00:05, 7281.82it/s]\u001b[A\n",
      " 67%|██████▋   | 81318/121267 [00:11<00:05, 7311.38it/s]\u001b[A\n",
      " 68%|██████▊   | 82079/121267 [00:11<00:05, 7341.67it/s]\u001b[A\n",
      " 68%|██████▊   | 82814/121267 [00:11<00:05, 7340.05it/s]\u001b[A\n",
      " 69%|██████▉   | 83585/121267 [00:11<00:05, 7392.58it/s]\u001b[A\n",
      " 70%|██████▉   | 84329/121267 [00:11<00:04, 7404.71it/s]\u001b[A\n",
      " 70%|███████   | 85085/121267 [00:11<00:04, 7392.83it/s]\u001b[A\n",
      " 71%|███████   | 85825/121267 [00:11<00:04, 7305.58it/s]\u001b[A\n",
      " 71%|███████▏  | 86556/121267 [00:11<00:04, 7292.54it/s]\u001b[A\n",
      " 72%|███████▏  | 87301/121267 [00:11<00:04, 7295.37it/s]\u001b[A\n",
      " 73%|███████▎  | 88033/121267 [00:12<00:04, 7287.15it/s]\u001b[A\n",
      " 73%|███████▎  | 88762/121267 [00:12<00:04, 7236.09it/s]\u001b[A\n",
      " 74%|███████▍  | 89486/121267 [00:12<00:04, 7200.96it/s]\u001b[A\n",
      " 74%|███████▍  | 90220/121267 [00:12<00:04, 7219.93it/s]\u001b[A\n",
      " 75%|███████▌  | 90971/121267 [00:12<00:04, 7263.08it/s]\u001b[A\n",
      " 76%|███████▌  | 91698/121267 [00:12<00:04, 7231.33it/s]\u001b[A\n",
      " 76%|███████▌  | 92434/121267 [00:12<00:03, 7247.83it/s]\u001b[A\n",
      " 77%|███████▋  | 93167/121267 [00:12<00:03, 7234.58it/s]\u001b[A\n",
      " 77%|███████▋  | 93919/121267 [00:12<00:03, 7257.50it/s]\u001b[A\n",
      " 78%|███████▊  | 94654/121267 [00:13<00:03, 7283.86it/s]\u001b[A\n",
      " 79%|███████▊  | 95386/121267 [00:13<00:03, 7234.00it/s]\u001b[A\n",
      " 79%|███████▉  | 96110/121267 [00:13<00:03, 7190.80it/s]\u001b[A\n",
      " 80%|███████▉  | 96841/121267 [00:13<00:03, 7207.81it/s]\u001b[A\n",
      " 80%|████████  | 97595/121267 [00:13<00:03, 7266.20it/s]\u001b[A\n",
      " 81%|████████  | 98333/121267 [00:13<00:03, 7277.89it/s]\u001b[A\n",
      " 82%|████████▏ | 99093/121267 [00:13<00:03, 7338.89it/s]\u001b[A\n",
      " 82%|████████▏ | 99848/121267 [00:13<00:02, 7363.73it/s]\u001b[A\n",
      " 83%|████████▎ | 100585/121267 [00:13<00:02, 7268.80it/s]\u001b[A\n",
      " 84%|████████▎ | 101313/121267 [00:13<00:02, 7250.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 102041/121267 [00:14<00:02, 7218.45it/s]\u001b[A\n",
      " 85%|████████▍ | 102764/121267 [00:14<00:02, 7180.49it/s]\u001b[A\n",
      " 85%|████████▌ | 103491/121267 [00:14<00:02, 7190.00it/s]\u001b[A\n",
      " 86%|████████▌ | 104214/121267 [00:14<00:02, 7159.91it/s]\u001b[A\n",
      " 87%|████████▋ | 104954/121267 [00:14<00:02, 7213.37it/s]\u001b[A\n",
      " 87%|████████▋ | 105715/121267 [00:14<00:02, 7286.59it/s]\u001b[A\n",
      " 88%|████████▊ | 106463/121267 [00:14<00:02, 7321.49it/s]\u001b[A\n",
      " 88%|████████▊ | 107196/121267 [00:14<00:01, 7248.95it/s]\u001b[A\n",
      " 89%|████████▉ | 107922/121267 [00:14<00:01, 7214.77it/s]\u001b[A\n",
      " 90%|████████▉ | 108650/121267 [00:14<00:01, 7205.60it/s]\u001b[A\n",
      " 90%|█████████ | 109408/121267 [00:15<00:01, 7284.94it/s]\u001b[A\n",
      " 91%|█████████ | 110152/121267 [00:15<00:01, 7305.15it/s]\u001b[A\n",
      " 91%|█████████▏| 110886/121267 [00:15<00:01, 7281.26it/s]\u001b[A\n",
      " 92%|█████████▏| 111615/121267 [00:15<00:01, 7249.41it/s]\u001b[A\n",
      " 93%|█████████▎| 112360/121267 [00:15<00:01, 7283.84it/s]\u001b[A\n",
      " 93%|█████████▎| 113089/121267 [00:15<00:01, 7236.61it/s]\u001b[A\n",
      " 94%|█████████▍| 113813/121267 [00:15<00:01, 7214.54it/s]\u001b[A\n",
      " 94%|█████████▍| 114550/121267 [00:15<00:00, 7222.08it/s]\u001b[A\n",
      " 95%|█████████▌| 115278/121267 [00:15<00:00, 7220.77it/s]\u001b[A\n",
      " 96%|█████████▌| 116011/121267 [00:15<00:00, 7214.50it/s]\u001b[A\n",
      " 96%|█████████▋| 116769/121267 [00:16<00:00, 7295.20it/s]\u001b[A\n",
      " 97%|█████████▋| 117519/121267 [00:16<00:00, 7322.79it/s]\u001b[A\n",
      " 98%|█████████▊| 118255/121267 [00:16<00:00, 7306.59it/s]\u001b[A\n",
      " 98%|█████████▊| 118992/121267 [00:16<00:00, 7280.10it/s]\u001b[A\n",
      " 99%|█████████▊| 119736/121267 [00:16<00:00, 7312.68it/s]\u001b[A\n",
      " 99%|█████████▉| 120468/121267 [00:16<00:00, 7260.67it/s]\u001b[A\n",
      "100%|█████████▉| 121195/121267 [00:16<00:00, 7244.36it/s]\u001b[A\n",
      "100%|██████████| 121267/121267 [00:16<00:00, 7272.67it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "#define transform function, define trainset and valset\n",
    "#AlexNet requires the input size of 224*224*3\n",
    "imgTransform = transforms.Compose([transforms.Scale((224)),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor()                       \n",
    "                            ])\n",
    "trainLoader, valLoader = dataLoader.get_train_valid_loader(cf.photo_url,50,32,'food',imgTransform,0.1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(train_loss,val_loss):\n",
    "    plt.plot(train_loss,'r',label = 'train loss')\n",
    "    plt.plot(val_loss,'b',label = 'validation loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss scores')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(train, val):\n",
    "    plt.plot(train,'r',label = 'train accuracy')\n",
    "    plt.plot(val,'b',label = 'validation accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy scores')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   0%|          | 2/2183 [00:04<1:49:33,  3.01s/it, accuracy=0, loss=13.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   0%|          | 3/2183 [00:04<1:18:51,  2.17s/it, accuracy=0, loss=13.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   0%|          | 6/2183 [00:05<31:05,  1.17it/s, accuracy=0, loss=11.8]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   0%|          | 8/2183 [00:05<18:09,  2.00it/s, accuracy=0.5, loss=52.6]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   0%|          | 9/2183 [00:06<23:55,  1.51it/s, accuracy=0.444, loss=49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   1%|          | 11/2183 [00:06<15:37,  2.32it/s, accuracy=0.364, loss=42.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 12/2183 [00:07<14:09,  2.56it/s, accuracy=0.333, loss=40.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 13/2183 [00:08<24:05,  1.50it/s, accuracy=0.308, loss=37.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   1%|          | 15/2183 [00:08<15:37,  2.31it/s, accuracy=0.267, loss=34.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 16/2183 [00:09<17:24,  2.08it/s, accuracy=0.25, loss=32.8] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 17/2183 [00:10<25:01,  1.44it/s, accuracy=0.235, loss=31.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   1%|          | 19/2183 [00:11<15:41,  2.30it/s, accuracy=0.211, loss=29]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 20/2183 [00:11<17:01,  2.12it/s, accuracy=0.2, loss=28]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 21/2183 [00:12<25:16,  1.43it/s, accuracy=0.19, loss=27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   1%|          | 23/2183 [00:13<16:15,  2.21it/s, accuracy=0.174, loss=25.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 24/2183 [00:13<15:27,  2.33it/s, accuracy=0.167, loss=24.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 25/2183 [00:14<24:16,  1.48it/s, accuracy=0.16, loss=24]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 26/2183 [00:15<19:11,  1.87it/s, accuracy=0.231, loss=23.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|          | 27/2183 [00:15<15:42,  2.29it/s, accuracy=0.296, loss=22.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|▏         | 28/2183 [00:16<18:19,  1.96it/s, accuracy=0.286, loss=22.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   1%|▏         | 30/2183 [00:17<19:06,  1.88it/s, accuracy=0.333, loss=21]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|▏         | 31/2183 [00:17<15:12,  2.36it/s, accuracy=0.323, loss=20.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   1%|▏         | 32/2183 [00:18<17:35,  2.04it/s, accuracy=0.438, loss=20.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   2%|▏         | 34/2183 [00:19<18:48,  1.90it/s, accuracy=0.412, loss=19.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   2%|▏         | 35/2183 [00:19<17:02,  2.10it/s, accuracy=0.571, loss=18.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training epoch 0:   2%|▏         | 36/2183 [00:20<15:19,  2.33it/s, accuracy=0.556, loss=18.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   2%|▏         | 38/2183 [00:21<19:57,  1.79it/s, accuracy=0.684, loss=17.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   2%|▏         | 39/2183 [00:21<16:27,  2.17it/s, accuracy=0.718, loss=17.3]Process Process-4:\n",
      "KeyboardInterrupt\n",
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process Process-2:\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"dataset.py\", line 45, in __getitem__\n",
      "  File \"dataset.py\", line 45, in __getitem__\n",
      "  File \"dataset.py\", line 45, in __getitem__\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    image = Image.open(img_address).convert('RGB')\n",
      "    image = Image.open(img_address).convert('RGB')\n",
      "    image = Image.open(img_address).convert('RGB')\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/PIL/Image.py\", line 857, in convert\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/PIL/Image.py\", line 857, in convert\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/PIL/Image.py\", line 857, in convert\n",
      "  File \"dataset.py\", line 45, in __getitem__\n",
      "    self.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self.load()\n",
      "Exception     self.load()\n",
      "    image = Image.open(img_address).convert('RGB')\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/PIL/ImageFile.py\", line 234, in load\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/PIL/ImageFile.py\", line 234, in load\n",
      "  File \"/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/PIL/Image.py\", line 2419, in open\n",
      "    n, err_code = decoder.decode(b)\n",
      "    prefix = fp.read(16)\n",
      "    n, err_code = decoder.decode(b)\n",
      "    s = read(self.decodermaxblock)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "_mysql_exceptions.ProgrammingError: (2014, \"Commands out of sync; you can't run this command now\") in <bound method Cursor.__del__ of <MySQLdb.cursors.Cursor object at 0x7f16d5efd810>> ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ea105a754529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# Train the previously defined model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-ea105a754529>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(network, criterion, optimizer, trainLoader, valLoader, n_epochs, use_gpu)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Training epoch %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This is important to call before training!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# Wrap inputs, and targets into torch.autograd.Variable types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/tqdm/_tqdm.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                 \u001b[0;31m# Update and print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aimin52qinhao/anaconda2/lib/python2.7/multiprocessing/queues.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m()\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mracquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0mrrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aimin52qinhao/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#define AlexNet CNN class\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1):\n",
    "        #change the num_classes 1000 to 1\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "#define train model\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = True):\n",
    "    \n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    \n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0)<50 or stars.size(0)<50: break\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                stars = stars.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            #set a rule: if prediction values is between real_value-0.5 and real_value+0.5, correct+1\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            larger = (pre_star.view(50) >= (stars.data-0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(50) <= (stars.data+0.5)).type(torch.IntTensor)\n",
    "            correct += (larger+littler).eq(2).sum() \n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "        train_accuracy.append(100 * correct / counter)\n",
    "        train_loss.append(cum_loss / (1 + i))\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0)<50 or stars.size(0)<50: break\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                stars = stars.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            larger = (pre_star.view(50) >= (stars.data-0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(50) <= (stars.data+0.5)).type(torch.IntTensor)\n",
    "            correct += (larger+littler).eq(2).sum() \n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "        val_accuracy.append(100 * correct / counter)\n",
    "        val_loss.append(cum_loss / (1 + i))\n",
    "    return [train_accuracy,val_accuracy,train_loss,val_loss]\n",
    "            \n",
    "#define learningRate\n",
    "learningRate = 1e-2 \n",
    "\n",
    "# Definition of our network.\n",
    "# network = models.alexnet(pretrained = True, num_classes=1)\n",
    "network = AlexNet()\n",
    "\n",
    "#Definition of our loss.\n",
    "#The MSELoss function (input? output?)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "result = []\n",
    "# Train the previously defined model.\n",
    "result = train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 20, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
