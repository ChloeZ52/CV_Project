{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import MySQLdb\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.sampler as smp\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import dataset\n",
    "import dataLoader\n",
    "import configure as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      " 62%|██████▏   | 75107/121267 [00:20<00:12, 3751.12it/s]"
     ]
    }
   ],
   "source": [
    "#define transform function, define trainset and valset\n",
    "#AlexNet requires the input size of 224*224*3\n",
    "imgTransform = transforms.Compose([transforms.Scale((224)),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor()                       \n",
    "                            ])\n",
    "trainLoader, valLoader = dataLoader.get_train_valid_loader(cf.photo_url,50,32,'food',imgTransform,0.1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(train_loss,val_loss):\n",
    "    plt.plot(train_loss,'r',label = 'train loss')\n",
    "    plt.plot(val_loss,'b',label = 'validation loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss scores')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(train, val):\n",
    "    plt.plot(train,'r',label = 'train accuracy')\n",
    "    plt.plot(val,'b',label = 'validation accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy scores')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define AlexNet CNN class\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1):\n",
    "        #change the num_classes 1000 to 1\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "#define train model\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = True):\n",
    "    \n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    \n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0)<50 or stars.size(0)<50: break\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                stars = stars.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            #set a rule: if prediction values is between real_value-0.5 and real_value+0.5, correct+1\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            print pre_star.size()\n",
    "            print stars.size()\n",
    "            larger = (pre_star.view(50) >= (stars.data-0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(50) <= (stars.data+0.5)).type(torch.IntTensor)\n",
    "            correct += (larger+littler).eq(2).sum() \n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "        train_accuracy.append(100 * correct / counter)\n",
    "        train_loss.append(cum_loss / (1 + i))\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0)<50 or stars.size(0)<50: break\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                stars = stars.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            print outputs.size()\n",
    "            print inputs.size()\n",
    "            print stars.size()\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            larger = (pre_star.view(50) >= (stars.data-0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(50) <= (stars.data+0.5)).type(torch.IntTensor)\n",
    "            correct += (larger+littler).eq(2).sum() \n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "        val_accuracy.append(100 * correct / counter)\n",
    "        val_loss.append(cum_loss / (1 + i))\n",
    "    return [train_accuracy,val_accuracy,train_loss,val_loss]\n",
    "            \n",
    "#define learningRate\n",
    "learningRate = 1e-2 \n",
    "\n",
    "# Definition of our network.\n",
    "# network = models.alexnet(pretrained = True, num_classes=1)\n",
    "network = AlexNet()\n",
    "\n",
    "#Definition of our loss.\n",
    "#The MSELoss function (input? output?)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(network.parameters(), lr = learningRate)\n",
    "\n",
    "result = []\n",
    "# Train the previously defined model.\n",
    "result = train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 20, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
