{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import MySQLdb\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.sampler as smp\n",
    "#from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm_nb\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import dataset\n",
    "import dataLoader\n",
    "import configure as cf\n",
    "import plot_utils as utils\n",
    "import train_function as train\n",
    "import resnet as modified_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_pretrained_model = modified_resnet.resnet50(pretrained = True)\n",
    "new_pretrained_model.fc = nn.Linear(512*4, 1)  \n",
    "new_pretrained_model.load_state_dict(torch.load('./Results/AllCategory/resnet_all_best'))\n",
    "new_pretrained_model = new_pretrained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = modified_resnet.resnet50(pretrained = True)\n",
    "classifier.fc = nn.Linear(512*4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.load_state_dict(torch.load('./Classification/Classification_Dropout/res_clas_do6'))\n",
    "classifier = classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 884/196278 [00:00<00:22, 8827.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After search photo, find result: 196278\n",
      "Start search stars for each photo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196278/196278 [00:24<00:00, 8040.95it/s]\n"
     ]
    }
   ],
   "source": [
    "imgTransform = transforms.Compose([transforms.Scale(256),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                                                        (0.2023, 0.1994, 0.2010))])\n",
    "trainLoader, valLoader = dataLoader.get_train_valid_loader(cf.photo_url,50,32,'all',imgTransform,0.1,1000, pin_memory = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.fusion = nn.Linear(4096, 1)\n",
    "        \n",
    "    def forward(self, feature):\n",
    "        result = self.fusion(feature)\n",
    "        return result\n",
    "        \n",
    "fusionModel = FusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fusionModel.load_state_dict(torch.load('./resnet_all_first'))\n",
    "fusionModel = fusionModel.eval().cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for par in fusionModel.parameters():\n",
    "    print par.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier = classifier.cuda(0).eval()\n",
    "new_pretrained_model = new_pretrained_model.cuda(0).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda5cab89e144b7184e9e055e3777ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503966894950/work/torch/lib/THC/generic/THCStorage.cu:66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4da67d929418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/razqtest1/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/razqtest1/anaconda2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/razqtest1/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/razqtest1/CV_Project/resnet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/razqtest1/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/razqtest1/anaconda2/lib/python2.7/site-packages/torch/nn/modules/batchnorm.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     35\u001b[0m         return F.batch_norm(\n\u001b[1;32m     36\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             self.training, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/razqtest1/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m    637\u001b[0m                training=False, momentum=0.1, eps=1e-5):\n\u001b[1;32m    638\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503966894950/work/torch/lib/THC/generic/THCStorage.cu:66"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "cum_loss = 0.0\n",
    "counter = 0\n",
    "batch_size = 50\n",
    "use_gpu = True\n",
    "#Definition of our loss.\n",
    "#The MSELoss function \n",
    "criterion = nn.MSELoss().cuda(1)\n",
    "if True:\n",
    "    t = tqdm_nb(valLoader, desc='Val epoch %d')\n",
    "else:\n",
    "    t = tqdm(valLoader, desc='Val epoch %d')\n",
    "fusionModel.train()  # This is important to call before evaluating!\n",
    "for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "    # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "    inputs = Variable(inputs)\n",
    "    stars = Variable(stars.type(torch.FloatTensor))\n",
    "    if inputs.size(0) < batch_size or stars.size(0) < batch_size: continue\n",
    "\n",
    "    if use_gpu:\n",
    "        inputs = inputs.cuda(0)\n",
    "        stars = stars.cuda(1)\n",
    "\n",
    "    # classifiy resnet feature extraction\n",
    "    f1 = classifier.conv1(inputs)\n",
    "    f1 = classifier.bn1(f1)\n",
    "    f1 = classifier.relu(f1)\n",
    "    f1 = classifier.maxpool(f1)\n",
    "\n",
    "    f1 = classifier.layer1(f1)\n",
    "    f1 = classifier.layer2(f1)\n",
    "    f1 = classifier.layer3(f1)\n",
    "    f1 = classifier.layer4(f1)\n",
    "\n",
    "    f1 = classifier.avgpool(f1)\n",
    "    f1 = f1.view(inputs.size(0), -1)\n",
    "\n",
    "    # regression resnet feature extraction\n",
    "    f2 = new_pretrained_model.conv1(inputs)\n",
    "    f2 = new_pretrained_model.bn1(f2)\n",
    "    f2 = new_pretrained_model.relu(f2)\n",
    "    f2 = new_pretrained_model.maxpool(f2)\n",
    "\n",
    "    f2 = new_pretrained_model.layer1(f2)\n",
    "    f2 = new_pretrained_model.layer2(f2)\n",
    "    f2 = new_pretrained_model.layer3(f2)\n",
    "    f2 = new_pretrained_model.layer4(f2)\n",
    "\n",
    "    f2 = new_pretrained_model.avgpool(f2)\n",
    "    f2 = f2.view(inputs.size(0), -1)\n",
    "    feature = torch.cat((f1,f2),1).cuda(1)\n",
    "\n",
    "    # Forward pass:\n",
    "    outputs = fusionModel(feature)\n",
    "    loss = criterion(outputs, stars)\n",
    "\n",
    "    # logging information.\n",
    "    cum_loss += loss.data[0]\n",
    "    pre_star = outputs.data\n",
    "    larger = (pre_star.view(batch_size) >= (stars.data - 0.5)).type(torch.IntTensor)\n",
    "    littler = (pre_star.view(batch_size) <= (stars.data + 0.5)).type(torch.IntTensor)\n",
    "    correct += (larger + littler).eq(2).sum()\n",
    "    counter += inputs.size(0)\n",
    "    temp_accuracy = 100 * correct / counter\n",
    "    temp_loss = cum_loss / (1 + i)\n",
    "    t.set_postfix(loss=temp_loss, accuracy=temp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define train model\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader,\n",
    "                n_epochs=10, use_gpu=True, batch_size=50, notebook=True, save_name = 'default'):\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    global classifier\n",
    "    global new_pretrained_model\n",
    "    classify = classifier\n",
    "    regress = new_pretrained_model\n",
    "    if use_gpu:\n",
    "        network = network.cuda(1)\n",
    "        criterion = criterion.cuda(1)\n",
    "\n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        temp_accuracy = 0\n",
    "        temp_loss = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        if notebook:\n",
    "            t = tqdm_nb(trainLoader, desc='Training epoch %d' % epoch)\n",
    "        else:\n",
    "            t = tqdm(trainLoader, desc='Training epoch %d' % epoch)\n",
    "        network.train() # This is important to call before training!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0) < batch_size or stars.size(0) < batch_size: continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda(0)\n",
    "                stars = stars.cuda(1)\n",
    "            \n",
    "            # classifiy resnet feature extraction\n",
    "            f1 = classify.conv1(inputs)\n",
    "            f1 = classify.bn1(f1)\n",
    "            f1 = classify.relu(f1)\n",
    "            f1 = classify.maxpool(f1)\n",
    "\n",
    "            f1 = classify.layer1(f1)\n",
    "            f1 = classify.layer2(f1)\n",
    "            f1 = classify.layer3(f1)\n",
    "            f1 = classify.layer4(f1)\n",
    "\n",
    "            f1 = classify.avgpool(f1)\n",
    "            f1 = f1.view(inputs.size(0), -1)\n",
    "\n",
    "            # regression resnet feature extraction\n",
    "            f2 = regress.conv1(inputs)\n",
    "            f2 = regress.bn1(f2)\n",
    "            f2 = regress.relu(f2)\n",
    "            f2 = regress.maxpool(f2)\n",
    "\n",
    "            f2 = regress.layer1(f2)\n",
    "            f2 = regress.layer2(f2)\n",
    "            f2 = regress.layer3(f2)\n",
    "            f2 = regress.layer4(f2)\n",
    "\n",
    "            f2 = regress.avgpool(f2)\n",
    "            f2 = f2.view(inputs.size(0), -1)\n",
    "            feature = torch.cat((f1,f2),1).cuda(1)\n",
    "            \n",
    "            # Forward pass:\n",
    "            outputs = network(feature)\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward()\n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            # set a rule: if prediction values is between real_value-0.5 and real_value+0.5, correct+1\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            larger = (pre_star.view(batch_size) >= (stars.data - 0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(batch_size) <= (stars.data + 0.5)).type(torch.IntTensor)\n",
    "            correct += (larger + littler).eq(2).sum()\n",
    "            counter += inputs.size(0)\n",
    "            temp_accuracy = 100 * correct / counter\n",
    "            temp_loss = cum_loss / (1 + i)\n",
    "            t.set_postfix(loss=temp_loss, accuracy=temp_accuracy)\n",
    "            del inputs, stars\n",
    "            \n",
    "        train_accuracy.append(temp_accuracy)\n",
    "        train_loss.append(temp_loss)\n",
    "        \n",
    "#         if(save_name != 'default'):\n",
    "#             torch.save(network.state_dict(), save_name + str(epoch))\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        if notebook:\n",
    "            t = tqdm_nb(valLoader, desc='Val epoch %d' % epoch)\n",
    "        else:\n",
    "            t = tqdm(valLoader, desc='Val epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, stars)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            stars = Variable(stars.type(torch.FloatTensor))\n",
    "            if inputs.size(0) < batch_size or stars.size(0) < batch_size: continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda(0)\n",
    "                stars = stars.cuda(1)\n",
    "\n",
    "            # classifiy resnet feature extraction\n",
    "            f1 = classify.conv1(inputs)\n",
    "            f1 = classify.bn1(f1)\n",
    "            f1 = classify.relu(f1)\n",
    "            f1 = classify.maxpool(f1)\n",
    "\n",
    "            f1 = classify.layer1(f1)\n",
    "            f1 = classify.layer2(f1)\n",
    "            f1 = classify.layer3(f1)\n",
    "            f1 = classify.layer4(f1)\n",
    "\n",
    "            f1 = classify.avgpool(f1)\n",
    "            f1 = f1.view(inputs.size(0), -1)\n",
    "\n",
    "            # regression resnet feature extraction\n",
    "            f2 = regress.conv1(inputs)\n",
    "            f2 = regress.bn1(f2)\n",
    "            f2 = regress.relu(f2)\n",
    "            f2 = regress.maxpool(f2)\n",
    "\n",
    "            f2 = regress.layer1(f2)\n",
    "            f2 = regress.layer2(f2)\n",
    "            f2 = regress.layer3(f2)\n",
    "            f2 = regress.layer4(f2)\n",
    "\n",
    "            f2 = regress.avgpool(f2)\n",
    "            f2 = f2.view(inputs.size(0), -1)\n",
    "            feature = torch.cat((f1,f2),1).cuda(1)\n",
    "            \n",
    "            # Forward pass:\n",
    "            outputs = network(feature)\n",
    "            loss = criterion(outputs, stars)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            pre_star = outputs.data\n",
    "            larger = (pre_star.view(batch_size) >= (stars.data - 0.5)).type(torch.IntTensor)\n",
    "            littler = (pre_star.view(batch_size) <= (stars.data + 0.5)).type(torch.IntTensor)\n",
    "            correct += (larger + littler).eq(2).sum()\n",
    "            counter += inputs.size(0)\n",
    "            temp_accuracy = 100 * correct / counter\n",
    "            temp_loss = cum_loss / (1 + i)\n",
    "            t.set_postfix(loss=temp_loss, accuracy=temp_accuracy)\n",
    "            del inputs, stars\n",
    "\n",
    "        val_accuracy.append(temp_accuracy)\n",
    "        val_loss.append(temp_loss)\n",
    "    return [train_accuracy, val_accuracy, train_loss, val_loss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#define learningRate\n",
    "learningRate = 1e-3 \n",
    "\n",
    "#Definition of our loss.\n",
    "#The MSELoss function \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Definition of optimization strategy.\n",
    "optimizer = optim.SGD(fusionModel.parameters(), lr = learningRate)\n",
    "\n",
    "# Train the previously defined model.\n",
    "result = train_model(fusionModel, criterion, optimizer, trainLoader,\n",
    "                           valLoader, n_epochs = 10, use_gpu = True, batch_size = 50, notebook = True, save_name = \"resnet_all_category\")\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the image here using matplotlib.\n",
    "def plot_image(tensor):\n",
    "    plt.figure()\n",
    "    # imshow needs a numpy array with the channel dimension\n",
    "    # as the the last dimension so we have to transpose things.\n",
    "    plt.imshow(tensor.numpy().transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_result_id(id):\n",
    "    img_address = yelpDataset.photo_dir + '/' + yelpDataset.photo_id[id]['id'] + '.jpg'\n",
    "    image = pil2tensor(Image.open(img_address).convert('RGB'))\n",
    "    plot_image(image)\n",
    "    getimg, star = yelpDataset.__getitem__(id)\n",
    "    print star\n",
    "    getimg = getimg.unsqueeze(0)\n",
    "    print classifier(Variable(getimg))\n",
    "    print new_pretrained_model(Variable(getimg))\n",
    "\n",
    "yelpDataset = dataset.YelpDataSet(cf.photo_url, 'all', imgTransform)\n",
    "    \n",
    "import random\n",
    "pil2tensor = transforms.ToTensor()\n",
    "for i in range(10):\n",
    "    id = random.randint(0,196277)\n",
    "    print id\n",
    "    plot_result_id(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_address = yelpDataset.photo_dir + '/' + yelpDataset.photo_id[id]['id'] + '.jpg'\n",
    "image = pil2tensor(Image.open(img_address).convert('RGB'))\n",
    "getimg, star = yelpDataset.__getitem__(id)\n",
    "getimg = getimg.unsqueeze(0)\n",
    "print getimg.size()\n",
    "\n",
    "print fusionModel(Variable(getimg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
